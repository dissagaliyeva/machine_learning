{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ridge & Lasso Regularization techniques\n",
    "In this notebook I'll attempt to test out Ridge & Lasso algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ridge Regression\n",
    "<b>When to use it?</b> When we create a Linear Regression model and want to make it more accurate on the test dataset.\n",
    "Therefore, we sacrifice the accuracy of the training set to make it predict better on the test data. Thus, making better\n",
    "predictions in the long-term.(Also known as bias-variance tradeoff)\n",
    "\n",
    "- Linear Regression reduces the <b>sum of squared error/residuals</b>, while Ridge reduces the <b>sum of squared residuals + penalty*magnitude</b>\n",
    "- Can be used in both linear & logistic regressions\n",
    "- Uses L2 regularization\n",
    "\n",
    "<b>Formula</b>: $$SSR + \\lambda * slope^2$$, where SSR is <b>sum of squared residuals</b>; $$\\lambda$$ is the\n",
    "<b>magnitude</b> of penalty; <b>slope</b> is the penalty itself\n",
    "\n",
    "### Important!\n",
    "Regularization doesn't require any preprocessing steps <b>except standardization</b>. It works by enriching the\n",
    "learning process using a penalization for too complex models to shrink (or reduce to zero)\n",
    "coefficients relative to variables that are irrelevant for your prediction term or are\n",
    "redundant, as they are highly correlated with others present in the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df = load_boston()\n",
    "boston = pd.DataFrame(df.data, columns=df.feature_names)\n",
    "boston['Price'] = df.target\n",
    "\n",
    "X = boston.iloc[:, :-1]\n",
    "y = boston.iloc[:, -1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNSTANDARDIZED\n",
      "In-sample score: 0.7434997532004697\n",
      "Out-sample score: 0.7112260057484908\n",
      "\n",
      "==================\n",
      "\n",
      "In-Sample MSE: 22.545481487421426\n",
      "Out-sample MSE: 21.51744423117739\n",
      "\n",
      "==================\n",
      "\n",
      "In-sample RSS: 7981.100446547185\n",
      "Out-sample RSS: 3270.651523138963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def results(algorithm, train, train_target, test, test_target, text=''):\n",
    "    print(text.upper())\n",
    "    # calculate score\n",
    "    print(f'In-sample score: {algorithm.score(train, train_target)}')\n",
    "    print(f'Out-sample score: {algorithm.score(test, test_target)}')\n",
    "\n",
    "    print('\\n==================\\n')\n",
    "\n",
    "    # calculate MSE (mean squared error)\n",
    "    train_pred = algorithm.predict(train)\n",
    "    test_pred = algorithm.predict(test)\n",
    "    print(f'In-Sample MSE: {mean_squared_error(train_target, train_pred)}')\n",
    "    print(f'Out-sample MSE: {mean_squared_error(test_target, test_pred)}')\n",
    "\n",
    "    print('\\n==================\\n')\n",
    "\n",
    "    # calculate RSS (residual sum squared)\n",
    "    print(f'In-sample RSS: {np.sum(np.square(train_target - train_pred))}')\n",
    "    print(f'Out-sample RSS: {np.sum(np.square(test_target - test_pred))}\\n')\n",
    "\n",
    "# linear regression first\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "linear = LinearRegression().fit(X_train, y_train)\n",
    "results(linear, X_train, y_train, X_test, y_test, text='unstandardized')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STANDARDIZED\n",
      "In-sample score: 0.7434997532004697\n",
      "Out-sample score: 0.7112260057484932\n",
      "\n",
      "==================\n",
      "\n",
      "In-Sample MSE: 0.2670646768826304\n",
      "Out-sample MSE: 0.25488696234522545\n",
      "\n",
      "==================\n",
      "\n",
      "In-sample RSS: 94.54089561645117\n",
      "Out-sample RSS: 38.74281827647427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# standardize & check results\n",
    "boston_stand = StandardScaler().fit_transform(boston)\n",
    "Xst = boston_stand[:, :-1]\n",
    "yst = boston_stand[:, -1]\n",
    "\n",
    "Xst_train, Xst_test, yst_train, yst_test = train_test_split(Xst, yst, test_size=0.3, random_state=42)\n",
    "linear_standardized = LinearRegression(normalize=True).fit(Xst_train, yst_train)\n",
    "results(linear_standardized, Xst_train, yst_train, Xst_test, yst_test, text='standardized')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE STANDARDIZED\n",
      "In-sample score: 0.7434821404219876\n",
      "Out-sample score: 0.7108092176450824\n",
      "\n",
      "==================\n",
      "\n",
      "In-Sample MSE: 0.26708301507549\n",
      "Out-sample MSE: 0.2552548412253697\n",
      "\n",
      "==================\n",
      "\n",
      "In-sample RSS: 94.54738733672346\n",
      "Out-sample RSS: 38.79873586625619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ridge\n",
    "ridge = Ridge(alpha=1).fit(Xst_train, yst_train)\n",
    "results(ridge, Xst_train, yst_train, Xst_test, yst_test, text='Ridge standardized')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "ridge_cv = RidgeCV(alphas=(0.01, 0.1, 1.0, 10.0), cv=5, store_cv_values=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}