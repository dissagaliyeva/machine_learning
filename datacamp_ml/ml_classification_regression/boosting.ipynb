{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Adaboost (Adaptive Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y, shuffle=True, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# instantiate a decision tree classifier\n",
    "dtc = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "\n",
    "# instantiate an adaboost classifier\n",
    "adaboost = AdaBoostClassifier(base_estimator=dtc, n_estimators=100).fit(X_train, y_train)\n",
    "y_pred_proba = adaboost.predict_proba(X_test)[:, 1]  # check why it's [:, 1]\n",
    "# print(y_pred_proba)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADABOOST ROC AUC score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# evaluate test set roc_auc_score\n",
    "roc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'ADABOOST ROC AUC score: {round(roc_score, 2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# initial Decision Tree's score with max-depth=1\n",
    "dtc_prob = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "dtc_prob.fit(X_train, y_train)\n",
    "dtc_roc_auc = roc_auc_score(y_test, dtc_prob.predict_proba(X_test)[:, 1])\n",
    "print(f'DECISION TREE ROC AUC score: {round(dtc_roc_auc, 2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE ROC AUC score: 0.9\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How to find estimators?\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n",
      "Best params: {'max_depth': 2, 'max_features': 0.8, 'min_samples_leaf': 0.06}\n",
      "Best CV score: 0.9423076923076923\n",
      "Tuned DT Classifier's score: 0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [2, 3, 4, 5, 5],\n",
    "    'min_samples_leaf': [.04, .06, .08],\n",
    "    'max_features': [.2, .4, .6, .8]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "print(dt.get_params())\n",
    "\n",
    "grid_search = GridSearchCV(dt, param_grid=params, scoring='accuracy', cv=10, n_jobs=-1).fit(X_train, y_train)\n",
    "print(f'Best params: {grid_search.best_params_}')\n",
    "print(f'Best CV score: {grid_search.best_score_}')\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(f'Tuned DT Classifier\\'s score: {best_estimator.score(X_test, y_test)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.965\n"
     ]
    }
   ],
   "source": [
    "# roc-auc version\n",
    "params_dt = {'max_depth': [2, 3, 4], 'min_samples_leaf': [.12, .14, .16, .18]}\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best parameters: {'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 0.1, 'n_estimators': 400}\n",
      "RMSE: 0.2861316917596507\n"
     ]
    }
   ],
   "source": [
    "# tuning Forest Hyperparameters\n",
    "params = {\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_samples_leaf': [.1, .2],\n",
    "    'max_features': ['log2', 'sqrt']\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid=params, cv=3,\n",
    "                              scoring='neg_mean_squared_error', verbose=1, n_jobs=-1).fit(X_train, y_train)\n",
    "print(f'Best parameters: {grid_search_rf.best_params_}')\n",
    "best_model = grid_search_rf.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "rmse = mse(y_test, y_pred)**(1/2)\n",
    "print(f'RMSE: {rmse}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score with Gradient Boosting Regressor: 4.0\n",
      "RMSE score with Linear Regression : 5.09\n",
      "RMSE score with AdaBoost : 6.88\n"
     ]
    }
   ],
   "source": [
    "X_b, y_b = load_boston(return_X_y=True)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_b, y_b, test_size=.3,\n",
    "                                                            shuffle=True, random_state=32)\n",
    "\n",
    "# instantiate GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=300, max_depth=1, random_state=15).fit(X_train_b, y_train_b)\n",
    "rmse_gradient = mse(y_test_b, gbr.predict(X_test_b))**(1/2)\n",
    "print(f'RMSE score with Gradient Boosting Regressor: {round(rmse_gradient, 2)}')\n",
    "\n",
    "# compare with LinearRegression\n",
    "lin_reg = LinearRegression().fit(X_train_b, y_train_b)\n",
    "rmse_linear = mse(y_test_b, lin_reg.predict(X_test_b))**(1/2)\n",
    "print(f'RMSE score with Linear Regression : {round(rmse_linear, 2)}')\n",
    "\n",
    "# compare with AdaBoostRegressor\n",
    "ada_reg = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=1),\n",
    "                            n_estimators=200, random_state=32).fit(X_train_b, y_train_b)\n",
    "rmse_adaboost = mse(y_test_b, ada_reg.predict(X_test_b))**(1/2)\n",
    "print(f'RMSE score with AdaBoost : {round(rmse_adaboost, 2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stochastic Gradient Boosting\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score with Stochastic Gradient Boosting : 3.76\n"
     ]
    }
   ],
   "source": [
    "# instantiate a stochastic regressor\n",
    "stochastic_boosting = GradientBoostingRegressor(max_depth=1, subsample=0.8, max_features=.2,\n",
    "                                                n_estimators=300, random_state=42)\n",
    "stochastic_boosting.fit(X_train_b, y_train_b)\n",
    "y_pred = stochastic_boosting.predict(X_test_b)\n",
    "rmse_stochastic = mse(y_test_b, y_pred)**(1/2)\n",
    "print(f'RMSE score with Stochastic Gradient Boosting : {round(rmse_stochastic, 2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}